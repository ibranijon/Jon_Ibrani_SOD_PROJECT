{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b030fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from sod_model import set_sod_model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb814f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "\n",
    "\n",
    "def load_trained_model():\n",
    "    model = set_sod_model()\n",
    "    opt = optimizer()\n",
    "\n",
    "    # Locate checkpoints folder (same folder as notebook + project files)\n",
    "    base = os.getcwd()\n",
    "    ckpt_dir = os.path.join(base, \"checkpoints\")\n",
    "\n",
    "    checkp = tf.train.Checkpoint(model=model, optimizer=opt)\n",
    "    manager = tf.train.CheckpointManager(checkp, ckpt_dir, max_to_keep=3)\n",
    "\n",
    "    if manager.latest_checkpoint:\n",
    "        print(f\"Loaded checkpoint: {manager.latest_checkpoint}\")\n",
    "        checkp.restore(manager.latest_checkpoint).expect_partial()\n",
    "    else:\n",
    "        print(\"No checkpoint found.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "model = load_trained_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daae202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_array(img_bgr):\n",
    "    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f02567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    input_tensor = tf.expand_dims(img, axis=0)\n",
    "    start = time.time()\n",
    "    pred = model(input_tensor, training=False)\n",
    "    end = time.time()\n",
    "\n",
    "    mask = (pred[0].numpy().squeeze() > 0.5).astype(np.float32)\n",
    "\n",
    "    return mask, end - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(img, mask):\n",
    "    overlay = img.copy()\n",
    "    overlay[..., 0] = np.maximum(overlay[..., 0], mask)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upload_box = widgets.FileUpload(\n",
    "    accept='image/*',\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "display(upload_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720bc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_uploaded_image():\n",
    "    if not upload_box.value:\n",
    "        print(\"Please upload an image first.\")\n",
    "        return\n",
    "\n",
    "    raw = upload_box.value\n",
    "\n",
    "    # Handle tuple OR dict formats\n",
    "    if isinstance(raw, (tuple, list)):\n",
    "        file_content = raw[0]['content']\n",
    "    elif isinstance(raw, dict):\n",
    "        file_content = list(raw.values())[0]['content']\n",
    "    else:\n",
    "        print(\"Unsupported upload format.\")\n",
    "        return\n",
    "\n",
    "    # Convert bytes → numpy image\n",
    "    img_bytes = np.frombuffer(file_content, np.uint8)\n",
    "    img_bgr = cv2.imdecode(img_bytes, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Preprocess → predict\n",
    "    img = preprocess_image_array(img_bgr)\n",
    "    mask, infer_time = predict(model, img)\n",
    "\n",
    "    # Display results\n",
    "    show_results(img, mask)\n",
    "    print(f\"Inference time: {infer_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_btn = widgets.Button(\n",
    "    description=\"Run Prediction\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "def on_click_run(b):\n",
    "    process_uploaded_image()\n",
    "\n",
    "run_btn.on_click(on_click_run)\n",
    "display(run_btn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
